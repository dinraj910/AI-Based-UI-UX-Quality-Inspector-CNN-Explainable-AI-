# -*- coding: utf-8 -*-
"""UI_UX_Quality_Inspector_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W7FY4fUGTwqVDyXGEOfPcxyxZSbWYK-i

# Mount Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Extract"""

import tarfile
import os

TAR_PATH = "/content/drive/MyDrive/unique_uis.tar.gz"
EXTRACT_PATH = "/content/uiux_data"

os.makedirs(EXTRACT_PATH, exist_ok=True)

with tarfile.open(TAR_PATH, "r:gz") as tar:
    tar.extractall(path=EXTRACT_PATH)

print("Dataset extracted successfully")

"""# Verify Extraction"""

os.listdir(EXTRACT_PATH)

for root, dirs, files in os.walk("/content/uiux_data/combined/"):
    if any(f.endswith(".png") for f in files):
        print("FOUND PNGs IN:", root)
        break

"""# Preview Random UI Screenshot"""

import os
import random
from PIL import Image
import matplotlib.pyplot as plt

SCREENSHOT_DIR = "/content/uiux_data/combined"
IMAGE_EXTS = (".jpg", ".jpeg", ".png")

images = [
    f for f in os.listdir(SCREENSHOT_DIR)
    if f.lower().endswith(IMAGE_EXTS)
]

print("Total UI images found:", len(images))

img_name = random.choice(images)
img_path = os.path.join(SCREENSHOT_DIR, img_name)

img = Image.open(img_path)
plt.imshow(img)
plt.axis("off")

"""# Create Project Folder Structure"""

BASE_DIR = "/content/uiux_project"

dirs = [
    "data/images/clean",
    "data/images/degraded_alignment",
    "data/images/degraded_spacing",
    "data/images/degraded_both"
]

for d in dirs:
    os.makedirs(os.path.join(BASE_DIR, d), exist_ok=True)

print("Project structure created")

"""# Prepare CLEAN UI Images"""

import shutil
import random
import os

BASE_DIR = "/content/uiux_project"
DST_CLEAN_DIR = f"{BASE_DIR}/data/images/clean"

os.makedirs(DST_CLEAN_DIR, exist_ok=True)

all_images = [
    f for f in os.listdir(SCREENSHOT_DIR)
    if f.lower().endswith((".jpg", ".jpeg", ".png"))
]

sample_images = random.sample(all_images, 500)  # start with 500

for img in sample_images:
    shutil.copy(
        os.path.join(SCREENSHOT_DIR, img),
        os.path.join(DST_CLEAN_DIR, img)
    )

print(f"Copied {len(sample_images)} clean UI images")

"""# Create Initial labels.csv"""

import pandas as pd

label_rows = []

for img in os.listdir(DST_CLEAN_DIR):
    label_rows.append({
        "image": img,
        "ux_score": 90,
        "alignment_issue": 0,
        "spacing_issue": 0
    })

labels_df = pd.DataFrame(label_rows)
labels_path = f"{BASE_DIR}/data/labels.csv"
labels_df.to_csv(labels_path, index=False)

labels_df.head()

labels_df.tail()

"""# Dataset Loader"""

import tensorflow as tf

IMAGE_SIZE = 256
UX_SCORE_SCALE = 100.0

def preprocess_image(path):
    img = tf.io.read_file(path)
    img = tf.image.decode_png(img, channels=3)
    img = tf.image.resize(img, (IMAGE_SIZE, IMAGE_SIZE))
    img = tf.cast(img, tf.float32) / 255.0
    return img


def make_dataset(df, image_root, batch_size=16, shuffle=True):
    image_paths = df["image"].apply(
        lambda x: os.path.join(image_root, x)
    ).values

    ux_scores = df["ux_score"].values / UX_SCORE_SCALE
    ux_flags = df[["alignment_issue", "spacing_issue"]].values

    ds = tf.data.Dataset.from_tensor_slices(
        (image_paths, (ux_scores, ux_flags))
    )

    def _map_fn(path, labels):
        img = preprocess_image(path)
        return img, labels

    ds = ds.map(_map_fn, num_parallel_calls=tf.data.AUTOTUNE)

    if shuffle:
        ds = ds.shuffle(len(df))

    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return ds

"""# Test Data Pipeline"""

labels = pd.read_csv(labels_path)

train_ds = make_dataset(
    labels,
    image_root=DST_CLEAN_DIR,
    batch_size=8
)

for images, (scores, flags) in train_ds.take(1):
    print("Images shape:", images.shape)
    print("UX scores shape:", scores.shape)
    print("UX flags shape:", flags.shape)

"""# Custom CNN Architecture"""

import tensorflow as tf
from tensorflow.keras import layers, models

def build_uiux_cnn(input_shape=(256, 256, 3)):
    inputs = layers.Input(shape=input_shape)

    # ----- Block 1 -----
    x = layers.Conv2D(32, 3, padding="same")(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(32, 3, padding="same")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.MaxPooling2D()(x)  # 128×128

    # ----- Block 2 -----
    x = layers.Conv2D(64, 3, padding="same")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(64, 3, padding="same")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.MaxPooling2D()(x)  # 64×64

    # ----- Block 3 -----
    x = layers.Conv2D(128, 3, padding="same")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(128, 3, padding="same")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.MaxPooling2D()(x)  # 32×32

    # ----- Block 4 -----
    x = layers.Conv2D(256, 3, padding="same")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(256, 3, padding="same")(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    # ----- Global Features -----
    x = layers.GlobalAveragePooling2D()(x)

    # ----- UX Score Head (Regression) -----
    ux_score = layers.Dense(1, name="ux_score")(x)

    # ----- UX Issue Head (Multi-label) -----
    ux_flags = layers.Dense(2, activation="sigmoid", name="ux_flags")(x)

    model = models.Model(inputs, outputs=[ux_score, ux_flags])
    return model

"""# Build & Inspect the Model"""

model = build_uiux_cnn()
model.summary()

"""# Compile the Model"""

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    loss={
        "ux_score": "mse",
        "ux_flags": "binary_crossentropy"
    },
    loss_weights={
        "ux_score": 1.0,
        "ux_flags": 1.0
    },
    metrics={
        "ux_score": "mae",
        "ux_flags": "accuracy"
    }
)

"""# Train the Model (INITIAL TRAINING)"""

history = model.fit(
    train_ds,
    epochs=10
)

"""# Plot Training Curves"""

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

# UX Score Loss
plt.subplot(1, 2, 1)
plt.plot(history.history["ux_score_loss"], label="UX Score Loss")
plt.legend()
plt.title("Regression Loss")

# UX Flags Loss
plt.subplot(1, 2, 2)
plt.plot(history.history["ux_flags_loss"], label="UX Flags Loss")
plt.legend()
plt.title("Classification Loss")

plt.show()

"""# Test a Single Prediction"""

import numpy as np

sample_batch = next(iter(train_ds))
images, (scores, flags) = sample_batch

pred_score, pred_flags = model.predict(images[:1])

print("Predicted UX score:", float(pred_score[0]) * 100)
print("Predicted UX flags:", pred_flags[0])

"""# Import Utilities for Image Manipulation"""

import cv2
import numpy as np
import os
import random
import pandas as pd

"""# Define Synthetic Degradation Functions"""

def degrade_alignment(img, max_shift=20):
    h, w, _ = img.shape
    shift_x = random.randint(-max_shift, max_shift)
    shift_y = random.randint(-max_shift, max_shift)

    M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])
    shifted = cv2.warpAffine(
        img, M, (w, h),
        borderMode=cv2.BORDER_REFLECT
    )
    return shifted

"""# Spacing Degradation (Local Cropping & Resize)"""

def degrade_spacing(img, crop_ratio=0.9):
    h, w, _ = img.shape
    ch, cw = int(h * crop_ratio), int(w * crop_ratio)

    start_y = random.randint(0, h - ch)
    start_x = random.randint(0, w - cw)

    cropped = img[start_y:start_y+ch, start_x:start_x+cw]
    resized = cv2.resize(cropped, (w, h))
    return resized

"""# Combined Degradation"""

def degrade_both(img):
    img = degrade_alignment(img)
    img = degrade_spacing(img)
    return img

"""# Generate Degraded Dataset"""

CLEAN_DIR = f"{BASE_DIR}/data/images/clean"
ALIGN_DIR = f"{BASE_DIR}/data/images/degraded_alignment"
SPACE_DIR = f"{BASE_DIR}/data/images/degraded_spacing"
BOTH_DIR  = f"{BASE_DIR}/data/images/degraded_both"

os.makedirs(ALIGN_DIR, exist_ok=True)
os.makedirs(SPACE_DIR, exist_ok=True)
os.makedirs(BOTH_DIR, exist_ok=True)

import os
new_labels = []

clean_images = os.listdir(CLEAN_DIR)

for img_name in clean_images:
    img_path = os.path.join(CLEAN_DIR, img_name)
    img = cv2.imread(img_path)

    if img is None:
        continue

    # Alignment degradation
    img_align = degrade_alignment(img)
    cv2.imwrite(os.path.join(ALIGN_DIR, img_name), img_align)
    new_labels.append([img_name, 65, 1, 0])

    # Spacing degradation
    img_space = degrade_spacing(img)
    cv2.imwrite(os.path.join(SPACE_DIR, img_name), img_space)
    new_labels.append([img_name, 65, 0, 1])

    # Combined degradation
    img_both = degrade_both(img)
    cv2.imwrite(os.path.join(BOTH_DIR, img_name), img_both)
    new_labels.append([img_name, 40, 1, 1])

labels_df = pd.read_csv(labels_path)

degraded_df = pd.DataFrame(
    new_labels,
    columns=["image", "ux_score", "alignment_issue", "spacing_issue"]
)

labels_df = pd.concat([labels_df, degraded_df], ignore_index=True)
labels_df.to_csv(labels_path, index=False)

print("Updated labels:", labels_df.shape)
labels_df.head()

"""# Build Full Training Dataset"""

def make_full_dataset(labels_df, batch_size=16):
    image_paths = []
    for _, row in labels_df.iterrows():
        if row["alignment_issue"] and row["spacing_issue"]:
            folder = BOTH_DIR
        elif row["alignment_issue"]:
            folder = ALIGN_DIR
        elif row["spacing_issue"]:
            folder = SPACE_DIR
        else:
            folder = CLEAN_DIR

        image_paths.append(os.path.join(folder, row["image"]))

    ux_scores = labels_df["ux_score"].values / UX_SCORE_SCALE
    ux_flags = labels_df[["alignment_issue", "spacing_issue"]].values

    ds = tf.data.Dataset.from_tensor_slices(
        (image_paths, (ux_scores, ux_flags))
    )

    def _map_fn(path, labels):
        img = preprocess_image(path)
        return img, labels

    ds = ds.map(_map_fn, num_parallel_calls=tf.data.AUTOTUNE)
    ds = ds.shuffle(len(labels_df)).batch(16).prefetch(tf.data.AUTOTUNE)
    return ds

full_ds = make_full_dataset(labels_df)

"""# Define Checkpoint + Early Stop"""

import tensorflow as tf

checkpoint_path = "/content/drive/MyDrive/uiux_checkpoint.keras"

checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path,
    monitor="loss",
    save_best_only=True,
    save_weights_only=False,
    verbose=1
)

earlystop_cb = tf.keras.callbacks.EarlyStopping(
    monitor="loss",
    patience=5,
    restore_best_weights=True,
    verbose=1
)

print("Checkpointing enabled. Model will be saved safely.")

"""# Reduce Compute Load NOW"""

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-4),
    loss={
        "ux_score": "mse",
        "ux_flags": "binary_crossentropy"
    },
    loss_weights={
        "ux_score": 1.0,
        "ux_flags": 1.0
    },
    metrics={
        "ux_score": "mae",
        "ux_flags": "accuracy"
    }
)

print("Model recompiled successfully after freezing layers.")

"""# REAL TRAINING"""

history = model.fit(
    full_ds,
    epochs=10,   # run in SAFE BLOCKS
    callbacks=[checkpoint_cb, earlystop_cb]
)

"""# Analyze Learning Curves"""

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history["ux_score_mae"])
plt.title("UX Score MAE")

plt.subplot(1, 2, 2)
plt.plot(history.history["ux_flags_accuracy"])
plt.title("UX Flags Accuracy")

plt.show()

"""# Sanity Test (Good vs Bad UI)"""

sample_clean = random.choice(os.listdir(CLEAN_DIR))
sample_bad = random.choice(os.listdir(BOTH_DIR))

def predict_ui(path):
    img = preprocess_image(path)
    img = tf.expand_dims(img, 0)
    score, flags = model.predict(img)
    return score[0][0] * 100, flags[0]

print("GOOD UI:", predict_ui(os.path.join(CLEAN_DIR, sample_clean)))
print("BAD UI:", predict_ui(os.path.join(BOTH_DIR, sample_bad)))

"""# Identify the Last Convolution Layer"""

model.summary()

"""# Grad-CAM Function (CORE LOGIC)"""

import tensorflow as tf
import numpy as np
import cv2

def compute_gradcam(model, image, layer_name, output_index=0):
    grad_model = tf.keras.models.Model(
        [model.inputs],
        [model.get_layer(layer_name).output, model.outputs]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(image)
        loss = predictions[output_index]

    grads = tape.gradient(loss, conv_outputs)

    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]

    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)
    heatmap = tf.maximum(heatmap, 0)
    heatmap /= tf.reduce_max(heatmap) + 1e-8

    return heatmap.numpy()

"""# Overlay Heatmap on UI Image"""

def overlay_heatmap(img_path, heatmap, alpha=0.5):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (256, 256))

    heatmap = cv2.resize(heatmap, (256, 256))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

    overlay = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)
    return img, overlay

"""# Run Grad-CAM on GOOD vs BAD UI"""

import random
import matplotlib.pyplot as plt

def explain_ui(image_path, title):
    img = preprocess_image(image_path)
    img_tensor = tf.expand_dims(img, 0)

    score, flags = model.predict(img_tensor)

    heatmap = compute_gradcam(
        model,
        img_tensor,
        LAST_CONV_LAYER,
        output_index=0  # UX score head
    )

    original, overlay = overlay_heatmap(image_path, heatmap)

    print(f"{title}")
    print(f"UX Score: {score[0][0] * 100:.2f}")
    print(f"Flags (alignment, spacing): {flags[0]}")

    plt.figure(figsize=(10, 4))
    plt.subplot(1, 2, 1)
    plt.imshow(original)
    plt.title("Original UI")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(overlay)
    plt.title("Grad-CAM Explanation")
    plt.axis("off")
    plt.show()

"""# Explain a CLEAN UI"""

good_ui = random.choice(os.listdir(CLEAN_DIR))
explain_ui(os.path.join(CLEAN_DIR, good_ui), "GOOD UI")

"""# Explain a DEGRADED UI"""

bad_ui = random.choice(os.listdir(BOTH_DIR))
explain_ui(os.path.join(BOTH_DIR, bad_ui), "BAD UI (Alignment + Spacing Issues)")

"""# Save final model"""

model.save("/content/drive/MyDrive/uiux_final_model.keras")
print("Final model saved successfully.")

from google.colab import files
files.download("/content/drive/MyDrive/uiux_final_model.keras")